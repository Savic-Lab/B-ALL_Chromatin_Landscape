#BSUB -P savicgrp
#BSUB -oo ATAC_Batch8_%J_%I.out
#BSUB -eo ATAC_Batch8_%J_%I.err
#BSUB -n 6
#BSUB -q standard
#BSUB -R "span[hosts=1] rusage[mem=6000]"
#BSUB -J "ATAC_Batch8[1-23]"
#BSUB -B

# Set up modules for pipeline
module purge
module load conda3/5.1.0
source activate trimgalore
module load bowtie2/2.2.9
module load samtools/1.2
module load picard/1.141
module load macs2/2.1.1
module load bedtools/2.30.0
module load R/4.0.2

# Make TSV file for array before running script
# paste <(ls -1 *R1_001.fastq.gz) <(ls -1 *_R2_001.fastq.gz) > fastq_list.tsv

# Setup variables used in pipeline
NCORE=6
BASE_DIR=
FASTQ_TSV=${BASE_DIR}/fastq_list.tsv
FQ_DIR=${BASE_DIR}
TRIM_DIR=${BASE_DIR}/trimmed_reads
FASTQC_DIR=${BASE_DIR}/fastqc
MAP_DIR=${BASE_DIR}/mapped_reads
PEAK_DIR=${BASE_DIR}/peaks
TEMP_DIR=${BASE_DIR}/temp
PICARD_HOME=/hpcf/apps/picard/install/1.141
BT_INDEX=/datasets/public/igenomes/hg19/Homo_sapiens/UCSC/hg19/Sequence/Bowtie2Index/genome

# Change to working directory where raw fastq files are
cd $FQ_DIR

# Parse tsv file to feed into array
id=$LSB_JOBINDEX
FASTQ1=`head -n $id ${FASTQ_TSV}|tail -n1|awk '{print $1}'`
FASTQ2=`head -n $id ${FASTQ_TSV}|tail -n1|awk '{print $2}'`
FILE=`basename $FASTQ1 _L004_R1_001.fastq.gz`

# Check if directories exist, if not, create them
if test -d ${TRIM_DIR}; then  echo "trimmed directory exists"; else mkdir ${TRIM_DIR} && echo created; fi
if test -d ${FASTQC_DIR}; then  echo "fastqc directory exists"; else mkdir ${FASTQC_DIR} && echo created; fi
if test -d ${MAP_DIR}; then  echo "mapped directory exists"; else mkdir ${MAP_DIR} && echo created; fi
if test -d ${PEAK_DIR}; then  echo "peak directory exists"; else mkdir ${PEAK_DIR} && echo created; fi
if test -d ${TEMP_DIR}; then  echo "temp directory exists"; else mkdir ${TEMP_DIR} && echo created; fi


### Trim raw sequencing reads and run fastqc
trim_galore --fastqc --fastqc_args "--threads $NCORE --outdir $FASTQC_DIR" --basename $FILE --output_dir $TRIM_DIR --paired $FASTQ1 $FASTQ2

### Map sequencing reads
bowtie2 -x $BT_INDEX -p $NCORE -X 2000 -1 ${TRIM_DIR}/${FILE}_val_1.fq.gz -2 ${TRIM_DIR}/${FILE}_val_2.fq.gz -S ${MAP_DIR}/${FILE}.sam

### Quality filter mapped reads and transform to bam
samtools view -q 20 -b ${MAP_DIR}/${FILE}.sam > ${MAP_DIR}/${FILE}_unsorted.bam

### Sort bam file
java -jar ${PICARD_HOME}/picard.jar SortSam \
	TMP_DIR=${TEMP_DIR} \
	I=${MAP_DIR}/${FILE}_unsorted.bam \
	O=${MAP_DIR}/${FILE}.bam \
	SORT_ORDER=coordinate

### Remove mitochondrial reads
samtools view -h ${MAP_DIR}/${FILE}.bam | awk '{if($3 != "chrM"){print $0}}' | samtools view -b - > ${MAP_DIR}/${FILE}_NOMT.bam

### Remove duplicates
java -jar ${PICARD_HOME}/picard.jar MarkDuplicates \
	TMP_DIR=${TEMP_DIR} \
	M=${MAP_DIR}/${FILE}.bam.dupstats.txt \
	REMOVE_DUPLICATES=TRUE \
	I=${MAP_DIR}/${FILE}_NOMT.bam \
	O=${MAP_DIR}/${FILE}_NODUPS_NOMT.bam

### Make coverage bedgraph from bam
bedtools genomecov -bg -ibam ${MAP_DIR}/${FILE}_NODUPS_NOMT.bam | gzip -c > ${MAP_DIR}/${FILE}_NODUPS_NOMT.coverage.bdg.gz

### Get insert size metrics
java -jar ${PICARD_HOME}/picard.jar CollectInsertSizeMetrics \
	TMP_DIR=${TEMP_DIR} \
	I=${MAP_DIR}/${FILE}_NODUPS_NOMT.bam \
	O=${MAP_DIR}/${FILE}_NODUPS_NOMT.insert_size_metrics.txt \
	H=${MAP_DIR}/${FILE}_NODUPS_NOMT.insert_size_histogram.pdf

### Call peaks
macs2 callpeak -t ${MAP_DIR}/${FILE}_NODUPS_NOMT.bam -f BAMPE -g hs --nomodel --extsize 200 --SPMR -B --trackline -n ${FILE} --outdir ${PEAK_DIR}
